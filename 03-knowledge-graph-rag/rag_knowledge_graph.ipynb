{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c651213",
   "metadata": {},
   "source": [
    "# Sistema RAG con Grafo de Conocimiento\n",
    "\n",
    "Este notebook implementa un sistema de Generación Aumentada por Recuperación (RAG) usando un grafo de conocimiento pre-construido para responder preguntas sobre lenguajes de programación, frameworks y conceptos tecnológicos.\n",
    "\n",
    "## Importar Librerías Requeridas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9278ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import networkx as nx\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af2e24",
   "metadata": {},
   "source": [
    "## Configurar Variables de Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b34425",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# Azure OpenAI API\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY_US\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT_US\"]\n",
    ")\n",
    "CHAT_DEPLOYMENT = os.environ[\"AZURE_OPENAI_DEPLOYMENT_CHAT\"]\n",
    "\n",
    "print(f\"Modelo configurado: {CHAT_DEPLOYMENT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519247bb",
   "metadata": {},
   "source": [
    "## Cargar Grafo de Conocimiento Serializado\n",
    "\n",
    "Cargar el grafo de conocimiento pre-construido desde disco para acceso instantáneo. El grafo contiene entidades y relaciones sobre conceptos tecnológicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788211ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph from pickle\n",
    "graph_pickle_path = Path(\"data/knowledge_graph.pkl\")\n",
    "\n",
    "print(\"Cargando grafo serializado...\")\n",
    "with open(graph_pickle_path, 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "\n",
    "# Extract entity dictionary\n",
    "entities = graph.graph['entities']\n",
    "\n",
    "print(f\"Grafo cargado:\")\n",
    "print(f\"  - Entidades: {graph.number_of_nodes()}\")\n",
    "print(f\"  - Relaciones: {graph.number_of_edges()}\")\n",
    "print(f\"  - Tipos de entidad: {set(data['type'] for _, data in graph.nodes(data=True))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02138353",
   "metadata": {},
   "source": [
    "## Definir Funciones de Búsqueda y Contexto\n",
    "\n",
    "Implementar búsqueda de entidades con puntuación basada en nombre, tipo y propiedades. También definir funciones para recuperar el contexto de entidades incluyendo relaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_entities(query: str, top_k: int = 5) -> List[Dict]:\n",
    "    \"\"\"Search entities by name or properties.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    query_tokens = [token for token in re.split(r\"\\W+\", query_lower) if token]\n",
    "    \n",
    "    if not query_tokens:\n",
    "        return []\n",
    "    \n",
    "    matches = []\n",
    "    for entity_id, entity in entities.items():\n",
    "        score = 0\n",
    "        \n",
    "        # Name matching\n",
    "        entity_name = entity['name'].lower()\n",
    "        name_matches = sum(1 for token in query_tokens if token in entity_name)\n",
    "        score += 10 * name_matches\n",
    "        \n",
    "        # Type matching\n",
    "        entity_type = entity['type'].lower()\n",
    "        type_matches = sum(1 for token in query_tokens if token in entity_type)\n",
    "        score += 5 * type_matches\n",
    "        \n",
    "        # Property matching\n",
    "        for key, value in entity.get('properties', {}).items():\n",
    "            key_lower = str(key).lower()\n",
    "            value_lower = str(value).lower()\n",
    "            prop_matches = sum(\n",
    "                1 for token in query_tokens \n",
    "                if token in key_lower or token in value_lower\n",
    "            )\n",
    "            score += 3 * prop_matches\n",
    "        \n",
    "        if score > 0:\n",
    "            matches.append({'entity': entity, 'score': score})\n",
    "    \n",
    "    matches.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return [m['entity'] for m in matches[:top_k]]\n",
    "\n",
    "\n",
    "def get_entity_context(entity_id: str) -> Dict:\n",
    "    \"\"\"Get entity and its immediate relationships.\"\"\"\n",
    "    if entity_id not in entities:\n",
    "        return None\n",
    "    \n",
    "    context = {\n",
    "        'entity': entities[entity_id],\n",
    "        'relationships': []\n",
    "    }\n",
    "    \n",
    "    # Outgoing relationships\n",
    "    for target in graph.successors(entity_id):\n",
    "        edge_data = graph.get_edge_data(entity_id, target)\n",
    "        context['relationships'].append({\n",
    "            'type': edge_data['rel_type'],\n",
    "            'direction': 'outgoing',\n",
    "            'target': entities[target],\n",
    "            'properties': edge_data.get('properties', {})\n",
    "        })\n",
    "    \n",
    "    # Incoming relationships\n",
    "    for source in graph.predecessors(entity_id):\n",
    "        edge_data = graph.get_edge_data(source, entity_id)\n",
    "        context['relationships'].append({\n",
    "            'type': edge_data['rel_type'],\n",
    "            'direction': 'incoming',\n",
    "            'source': entities[source],\n",
    "            'properties': edge_data.get('properties', {})\n",
    "        })\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def format_context_for_llm(contexts: List[Dict]) -> str:\n",
    "    \"\"\"Format graph contexts for LLM consumption.\"\"\"\n",
    "    if not contexts:\n",
    "        return \"No se encontró información relevante en el grafo de conocimiento.\"\n",
    "    \n",
    "    formatted = \"Información del Grafo de Conocimiento:\\n\\n\"\n",
    "    \n",
    "    for i, ctx in enumerate(contexts, 1):\n",
    "        entity = ctx['entity']\n",
    "        formatted += f\"Entidad #{i}: {entity['name']} ({entity['type']})\\n\"\n",
    "        \n",
    "        # Properties\n",
    "        if entity.get('properties'):\n",
    "            formatted += \"  Propiedades:\\n\"\n",
    "            for key, value in entity['properties'].items():\n",
    "                formatted += f\"    - {key}: {value}\\n\"\n",
    "        \n",
    "        # Relationships\n",
    "        if ctx['relationships']:\n",
    "            formatted += \"  Relaciones:\\n\"\n",
    "            for rel in ctx['relationships']:\n",
    "                if rel['direction'] == 'outgoing':\n",
    "                    formatted += f\"    - {rel['type']} -> {rel['target']['name']} ({rel['target']['type']})\\n\"\n",
    "                else:\n",
    "                    formatted += f\"    - {rel['type']} <- {rel['source']['name']} ({rel['source']['type']})\\n\"\n",
    "                \n",
    "                # Relationship properties\n",
    "                if rel.get('properties'):\n",
    "                    for key, value in rel['properties'].items():\n",
    "                        formatted += f\"      {key}: {value}\\n\"\n",
    "        \n",
    "        formatted += \"\\n\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "print(\"Funciones de búsqueda definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905cbbe0",
   "metadata": {},
   "source": [
    "## Definir Mensajes de Sistema para el LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_REWRITE_SYSTEM_MESSAGE = \"\"\"\n",
    "Eres un asistente útil que reescribe preguntas de usuarios en consultas de palabras clave\n",
    "para buscar en un grafo de conocimiento sobre tecnología, lenguajes de programación, frameworks y conceptos.\n",
    "\n",
    "Extrae las entidades clave, conceptos o temas sobre los que pregunta el usuario.\n",
    "Enfócate en nombres específicos de lenguajes, frameworks, librerías, organizaciones o conceptos técnicos.\n",
    "\n",
    "Responde SOLO con la consulta de palabras clave (2-6 palabras).\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "Eres un asistente útil que responde preguntas usando un grafo de conocimiento sobre\n",
    "tecnología, lenguajes de programación, frameworks, librerías y conceptos relacionados.\n",
    "\n",
    "Debes basar tus respuestas en los datos del grafo de conocimiento proporcionados en el contexto.\n",
    "Si la información no está en el grafo de conocimiento, indícalo claramente.\n",
    "Usa las relaciones y propiedades para proporcionar respuestas completas y precisas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121611db",
   "metadata": {},
   "source": [
    "## Función de Respuesta a Preguntas\n",
    "\n",
    "Definir una función para procesar preguntas individuales a través del pipeline RAG: reescritura de consulta, búsqueda de entidades, recuperación de contexto y generación de respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b78f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question: str) -> str:\n",
    "    \"\"\"Ask a single question to the RAG system.\"\"\"\n",
    "    messages_local = [{\"role\": \"system\", \"content\": SYSTEM_MESSAGE}]\n",
    "    \n",
    "    # Rewrite query\n",
    "    response = client.chat.completions.create(\n",
    "        model=CHAT_DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": QUERY_REWRITE_SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": f\"Nueva pregunta del usuario: {question}\"},\n",
    "        ],\n",
    "    )\n",
    "    search_query = response.choices[0].message.content\n",
    "    \n",
    "    # Search and get context\n",
    "    found_entities = search_entities(search_query, top_k=5)\n",
    "    \n",
    "    if found_entities:\n",
    "        contexts = [get_entity_context(e['id']) for e in found_entities if get_entity_context(e['id'])]\n",
    "        graph_context = format_context_for_llm(contexts)\n",
    "    else:\n",
    "        graph_context = \"No se encontró información relevante.\"\n",
    "    \n",
    "    print(f\"\\n[Consulta de búsqueda]:\\n{search_query}\")\n",
    "    print(f\"\\n[Contexto]:\\n{graph_context}\")\n",
    "\n",
    "    # Generate answer\n",
    "    messages_local.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{question}\\n\\nContexto:\\n{graph_context}\"\n",
    "    })\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=CHAT_DEPLOYMENT,\n",
    "        messages=messages_local\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29ecbe",
   "metadata": {},
   "source": [
    "## Ejemplos de prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Query about Python's use cases\n",
    "answer = ask_question(\"¿Para qué se usa Python?\")\n",
    "print(f\"\\n[Respuesta]:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Compare web frameworks\n",
    "answer = ask_question(\"Háblame sobre GPT\")\n",
    "print(f\"\\n[Respuesta]:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174882c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Query about relationships between technologies\n",
    "answer = ask_question(\"¿Qué frameworks están construidos con JavaScript y para qué se usan?\")\n",
    "print(f\"\\n[Respuesta]:\\n{answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
