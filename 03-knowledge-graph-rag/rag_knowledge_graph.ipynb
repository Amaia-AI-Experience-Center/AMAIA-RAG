{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c651213",
   "metadata": {},
   "source": [
    "# Knowledge Graph RAG System\n",
    "\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) system using a pre-built knowledge graph to answer questions about programming languages, frameworks, and technology concepts.\n",
    "\n",
    "## Import Required Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9278ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import networkx as nx\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af2e24",
   "metadata": {},
   "source": [
    "## Configure Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b34425",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# OpenAI/GitHub Models API\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"https://models.github.ai/inference\", \n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"]\n",
    ")\n",
    "MODEL_NAME = os.getenv(\"GITHUB_MODEL\", \"openai/gpt-4o\")\n",
    "\n",
    "print(f\"✓ Model configured: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519247bb",
   "metadata": {},
   "source": [
    "## Load Serialized Knowledge Graph\n",
    "\n",
    "Load the pre-built knowledge graph from disk for instant access. The graph contains entities and relationships about technology concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788211ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph from pickle\n",
    "graph_pickle_path = Path(\"data/knowledge_graph.pkl\")\n",
    "\n",
    "print(\"Loading serialized graph...\")\n",
    "with open(graph_pickle_path, 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "\n",
    "# Extract entity dictionary\n",
    "entities = graph.graph['entities']\n",
    "\n",
    "print(f\"✓ Graph loaded:\")\n",
    "print(f\"  - Entities: {graph.number_of_nodes()}\")\n",
    "print(f\"  - Relationships: {graph.number_of_edges()}\")\n",
    "print(f\"  - Entity types: {set(data['type'] for _, data in graph.nodes(data=True))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02138353",
   "metadata": {},
   "source": [
    "## Define Search and Context Functions\n",
    "\n",
    "Implement entity search with scoring based on name, type, and properties. Also define functions to retrieve entity context including relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_entities(query: str, top_k: int = 5) -> List[Dict]:\n",
    "    \"\"\"Search entities by name or properties.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    query_tokens = [token for token in re.split(r\"\\W+\", query_lower) if token]\n",
    "    \n",
    "    if not query_tokens:\n",
    "        return []\n",
    "    \n",
    "    matches = []\n",
    "    for entity_id, entity in entities.items():\n",
    "        score = 0\n",
    "        \n",
    "        # Name matching\n",
    "        entity_name = entity['name'].lower()\n",
    "        name_matches = sum(1 for token in query_tokens if token in entity_name)\n",
    "        score += 10 * name_matches\n",
    "        \n",
    "        # Type matching\n",
    "        entity_type = entity['type'].lower()\n",
    "        type_matches = sum(1 for token in query_tokens if token in entity_type)\n",
    "        score += 5 * type_matches\n",
    "        \n",
    "        # Property matching\n",
    "        for key, value in entity.get('properties', {}).items():\n",
    "            key_lower = str(key).lower()\n",
    "            value_lower = str(value).lower()\n",
    "            prop_matches = sum(\n",
    "                1 for token in query_tokens \n",
    "                if token in key_lower or token in value_lower\n",
    "            )\n",
    "            score += 3 * prop_matches\n",
    "        \n",
    "        if score > 0:\n",
    "            matches.append({'entity': entity, 'score': score})\n",
    "    \n",
    "    matches.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return [m['entity'] for m in matches[:top_k]]\n",
    "\n",
    "\n",
    "def get_entity_context(entity_id: str) -> Dict:\n",
    "    \"\"\"Get entity and its immediate relationships.\"\"\"\n",
    "    if entity_id not in entities:\n",
    "        return None\n",
    "    \n",
    "    context = {\n",
    "        'entity': entities[entity_id],\n",
    "        'relationships': []\n",
    "    }\n",
    "    \n",
    "    # Outgoing relationships\n",
    "    for target in graph.successors(entity_id):\n",
    "        edge_data = graph.get_edge_data(entity_id, target)\n",
    "        context['relationships'].append({\n",
    "            'type': edge_data['rel_type'],\n",
    "            'direction': 'outgoing',\n",
    "            'target': entities[target],\n",
    "            'properties': edge_data.get('properties', {})\n",
    "        })\n",
    "    \n",
    "    # Incoming relationships\n",
    "    for source in graph.predecessors(entity_id):\n",
    "        edge_data = graph.get_edge_data(source, entity_id)\n",
    "        context['relationships'].append({\n",
    "            'type': edge_data['rel_type'],\n",
    "            'direction': 'incoming',\n",
    "            'source': entities[source],\n",
    "            'properties': edge_data.get('properties', {})\n",
    "        })\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def format_context_for_llm(contexts: List[Dict]) -> str:\n",
    "    \"\"\"Format graph contexts for LLM consumption.\"\"\"\n",
    "    if not contexts:\n",
    "        return \"No relevant information found in the knowledge graph.\"\n",
    "    \n",
    "    formatted = \"Knowledge Graph Information:\\n\\n\"\n",
    "    \n",
    "    for i, ctx in enumerate(contexts, 1):\n",
    "        entity = ctx['entity']\n",
    "        formatted += f\"Entity #{i}: {entity['name']} ({entity['type']})\\n\"\n",
    "        \n",
    "        # Properties\n",
    "        if entity.get('properties'):\n",
    "            formatted += \"  Properties:\\n\"\n",
    "            for key, value in entity['properties'].items():\n",
    "                formatted += f\"    - {key}: {value}\\n\"\n",
    "        \n",
    "        # Relationships\n",
    "        if ctx['relationships']:\n",
    "            formatted += \"  Relationships:\\n\"\n",
    "            for rel in ctx['relationships']:\n",
    "                if rel['direction'] == 'outgoing':\n",
    "                    formatted += f\"    - {rel['type']} -> {rel['target']['name']} ({rel['target']['type']})\\n\"\n",
    "                else:\n",
    "                    formatted += f\"    - {rel['type']} <- {rel['source']['name']} ({rel['source']['type']})\\n\"\n",
    "                \n",
    "                # Relationship properties\n",
    "                if rel.get('properties'):\n",
    "                    for key, value in rel['properties'].items():\n",
    "                        formatted += f\"      {key}: {value}\\n\"\n",
    "        \n",
    "        formatted += \"\\n\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "print(\"✓ Search functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905cbbe0",
   "metadata": {},
   "source": [
    "## Define System Messages for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_REWRITE_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a helpful assistant that rewrites user questions into keyword queries\n",
    "for searching a knowledge graph about technology, programming languages, frameworks, and concepts.\n",
    "\n",
    "Extract the key entities, concepts, or topics the user is asking about.\n",
    "Focus on specific names of languages, frameworks, libraries, organizations, or technical concepts.\n",
    "\n",
    "Respond with ONLY the keyword query (2-6 words).\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are a helpful assistant that answers questions using a knowledge graph about\n",
    "technology, programming languages, frameworks, libraries, and related concepts.\n",
    "\n",
    "You must base your answers on the knowledge graph data provided in the context.\n",
    "If the information is not in the knowledge graph, say so clearly.\n",
    "Use the relationships and properties to provide comprehensive and accurate answers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121611db",
   "metadata": {},
   "source": [
    "## Question Answering Function\n",
    "\n",
    "Define a function to process individual questions through the RAG pipeline: query rewriting, entity search, context retrieval, and answer generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b78f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question: str) -> str:\n",
    "    \"\"\"Ask a single question to the RAG system.\"\"\"\n",
    "    messages_local = [{\"role\": \"system\", \"content\": SYSTEM_MESSAGE}]\n",
    "    \n",
    "    # Rewrite query\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        temperature=0.05,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": QUERY_REWRITE_SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": f\"New user question: {question}\"},\n",
    "        ],\n",
    "    )\n",
    "    search_query = response.choices[0].message.content\n",
    "    \n",
    "    # Search and get context\n",
    "    found_entities = search_entities(search_query, top_k=5)\n",
    "    \n",
    "    if found_entities:\n",
    "        contexts = [get_entity_context(e['id']) for e in found_entities if get_entity_context(e['id'])]\n",
    "        graph_context = format_context_for_llm(contexts)\n",
    "    else:\n",
    "        graph_context = \"No relevant information found.\"\n",
    "    \n",
    "    print(f\"\\n[Search query]:\\n{search_query}\")\n",
    "    print(f\"\\n[Context]:\\n{graph_context}\")\n",
    "\n",
    "    # Generate answer\n",
    "    messages_local.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{question}\\n\\nContext:\\n{graph_context}\"\n",
    "    })\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        temperature=0.3,\n",
    "        messages=messages_local\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29ecbe",
   "metadata": {},
   "source": [
    "## Ejemplos de prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Query about Python's use cases\n",
    "answer = ask_question(\"What is Python used for?\")\n",
    "print(f\"\\n[Answer]:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Compare web frameworks\n",
    "answer = ask_question(\"Tell me about GPT\")\n",
    "print(f\"\\n[Answer]:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174882c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Query about relationships between technologies\n",
    "answer = ask_question(\"What frameworks are built with JavaScript and what are they used for?\")\n",
    "print(f\"\\n[Answer]:\\n{answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
