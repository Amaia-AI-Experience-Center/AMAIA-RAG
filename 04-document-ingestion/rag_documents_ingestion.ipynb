{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e817a0",
   "metadata": {},
   "source": "# Pipeline de Ingesta de Documentos\n## Ingesta de Documentos PDF con Embeddings y Tags Automáticos\n\nEste notebook implementa un pipeline completo para:\n1. Extraer texto de archivos PDF\n2. Dividir en chunks procesables\n3. Generar embeddings con Azure OpenAI\n4. Clasificar automáticamente con tags relevantes usando LLM\n5. Guardar metadatos enriquecidos en JSON"
  },
  {
   "cell_type": "markdown",
   "id": "87863851",
   "metadata": {},
   "source": "## 1. Configuración de Variables de Entorno y Dependencias"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f1c52",
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nimport pathlib\nfrom openai import AzureOpenAI\nimport pymupdf4llm\nfrom dotenv import load_dotenv\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom typing import List, Dict, Any\n\n# Load environment variables\nload_dotenv(override=True)\n\n# Initialize Azure OpenAI client\nclient = AzureOpenAI(\n    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n)\nCHAT_DEPLOYMENT = os.environ[\"AZURE_OPENAI_DEPLOYMENT_CHAT\"]\nEMBEDDING_DEPLOYMENT = os.environ[\"AZURE_OPENAI_DEPLOYMENT_EMBEDDING\"]\n\n# Define directories\ndata_dir = pathlib.Path.cwd() / \"data\"\ndata_dir.mkdir(exist_ok=True)\n\nprint(f\"Librerías importadas correctamente\")\nprint(f\"Variables de entorno cargadas\")\nprint(f\"Directorio de datos: {data_dir}\")\nprint(f\"Modelo de chat: {CHAT_DEPLOYMENT}\")\nprint(f\"Modelo de embeddings: {EMBEDDING_DEPLOYMENT}\")"
  },
  {
   "cell_type": "markdown",
   "id": "e29bc4c7",
   "metadata": {},
   "source": "## 2. Cargar y Extraer Texto de Archivos PDF"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97acdf6",
   "metadata": {},
   "outputs": [],
   "source": "# Find all PDF files in data directory\nfilenames = [f.name for f in data_dir.glob(\"*.pdf\")]\n\nprint(f\"\\nArchivos PDF encontrados: {len(filenames)}\")\nfor i, filename in enumerate(filenames, 1):\n    print(f\"   {i}. {filename}\")\n\n# Dictionary to store extracted text from each file\nextracted_documents = {}\n\nfor filename in filenames:\n    file_path = data_dir / filename\n    print(f\"\\nProcesando: {filename}\")\n    \n    try:\n        # Extract text from PDF to markdown format\n        md_text = pymupdf4llm.to_markdown(file_path)\n        extracted_documents[filename] = md_text\n        \n        print(f\"   Texto extraído: {len(md_text)} caracteres\")\n        print(f\"   Preview: {md_text[:150]}...\")\n    except Exception as e:\n        print(f\"   Error al procesar: {e}\")"
  },
  {
   "cell_type": "markdown",
   "id": "75bfbdd2",
   "metadata": {},
   "source": "## 3. Dividir Texto en Chunks"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984661cd",
   "metadata": {},
   "outputs": [],
   "source": "# Configure text splitter\ntext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n    model_name=\"gpt-4o\",\n    chunk_size=500,\n    chunk_overlap=125\n)\n\n# Store all chunks\nall_chunks_raw = {}\n\nprint(f\"\\nDividiendo documentos en chunks...\")\nfor filename, md_text in extracted_documents.items():\n    texts = text_splitter.create_documents([md_text])\n    all_chunks_raw[filename] = texts\n    \n    print(f\"   {filename}: {len(texts)} chunks\")\n    \n    # Show first chunk as example\n    if texts:\n        print(f\"      Ejemplo - Chunk 1: {texts[0].page_content[:100]}...\")\n\nprint(f\"\\nChunking completado\")"
  },
  {
   "cell_type": "markdown",
   "id": "524a368e",
   "metadata": {},
   "source": [
    "## 4. Clasificar Chunks con LLM y Extraer Tags\n",
    "\n",
    "Se usará un modelo LLM para analizar automáticamente cada chunk y extraer tags relevantes de la lista predefinida.\n",
    "\n",
    "**Tags disponibles:**\n",
    "- introduccion\n",
    "- barrios\n",
    "- gastronomia\n",
    "- museos\n",
    "- eventos\n",
    "- naturaleza\n",
    "- vida_nocturna\n",
    "- transporte\n",
    "- excursiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815544da",
   "metadata": {},
   "outputs": [],
   "source": "# Define available tags\nAVAILABLE_TAGS = [\n    \"introduccion\",\n    \"barrios\",\n    \"gastronomia\",\n    \"museos\",\n    \"eventos\",\n    \"naturaleza\",\n    \"vida_nocturna\",\n    \"transporte\",\n    \"excursiones\"\n]\n\ndef extract_tags_from_chunk(text: str) -> List[str]:\n    \"\"\"\n    Use an LLM to extract relevant tags from chunk content.\n    \n    Args:\n        text: Chunk content\n    \n    Returns:\n        List of relevant tags\n    \"\"\"\n    try:\n        prompt = f\"\"\"Analiza el siguiente texto y AÑADE SOLO SI SE MENCIONA EXPLICITAMENTE algo relacionado con uno o mas de estos tags: \n{', '.join(AVAILABLE_TAGS)}\n\nTexto: {text[:1000]}\n\nResponde SOLO con una lista de tags en formato JSON, ejemplo: [\"tag1\", \"tag2\"]\nSin texto adicional, solo el JSON.\"\"\"\n        \n        response = client.chat.completions.create(\n            model=CHAT_DEPLOYMENT,\n            messages=[\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            temperature=0.3,\n            max_tokens=100\n        )\n        \n        # Parse JSON response\n        response_text = response.choices[0].message.content.strip()\n        tags = json.loads(response_text)\n        \n        # Validate that all tags are in the allowed list\n        valid_tags = [tag for tag in tags if tag in AVAILABLE_TAGS]\n        return valid_tags if valid_tags else [\"introduccion\"]\n        \n    except Exception as e:\n        print(f\"   Error al extraer tags: {e}\")\n        return [\"introduccion\"]\n\nprint(\"Función de extracción de tags definida\")"
  },
  {
   "cell_type": "markdown",
   "id": "6cbddccf",
   "metadata": {},
   "source": "## 5. Generar Embeddings con Azure OpenAI"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789109ba",
   "metadata": {},
   "outputs": [],
   "source": "def generate_embedding(text: str) -> List[float]:\n    \"\"\"\n    Generate an embedding for a text using Azure OpenAI.\n    \n    Args:\n        text: Text to generate embedding for\n    \n    Returns:\n        Embedding vector (list of floats)\n    \"\"\"\n    try:\n        response = client.embeddings.create(\n            model=EMBEDDING_DEPLOYMENT,\n            input=text\n        )\n        return response.data[0].embedding\n    except Exception as e:\n        print(f\"   Error al generar embedding: {e}\")\n        return []\n\nprint(\"Función de generación de embeddings definida\")"
  },
  {
   "cell_type": "markdown",
   "id": "0cbb5b50",
   "metadata": {},
   "source": [
    "## 6. Estructurar Datos con Metadatos\n",
    "\n",
    "Crear la estructura completa con: id, content, category (nombre del archivo), source, tags, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58acf9f",
   "metadata": {},
   "outputs": [],
   "source": "all_chunks = []\nchunk_counter = 1\n\nprint(f\"\\nProcesando chunks con metadatos...\")\n\nfor filename, chunks in all_chunks_raw.items():\n    print(f\"   {filename}\")\n    \n    for i, chunk in enumerate(chunks, 1):\n        try:\n            text_content = chunk.page_content\n            \n            # Extract tags using LLM\n            print(f\"      Chunk {i}/{len(chunks)}: extrayendo tags...\", end=\"\")\n            tags = extract_tags_from_chunk(text_content)\n            print(f\" {tags}\")\n            \n            # Generate embedding\n            print(f\"      Chunk {i}/{len(chunks)}: generando embedding...\", end=\"\")\n            embedding = generate_embedding(text_content)\n            print(f\" OK\")\n            \n            # Create chunk structure with all metadata\n            chunk_data = {\n                \"id\": f\"{filename.replace('.', '_')}-{i}\",\n                \"content\": text_content,\n                \"category\": filename.replace(\".pdf\", \"\"),  # Filename without extension\n                \"source\": \"pdf_ingestion\",  # Document source\n                \"tags\": tags,\n                \"embedding\": embedding\n            }\n            \n            all_chunks.append(chunk_data)\n            chunk_counter += 1\n            \n        except Exception as e:\n            print(f\"      Error al procesar chunk {i}: {e}\")\n\nprint(f\"\\nProcesamiento completado: {len(all_chunks)} chunks generados\")"
  },
  {
   "cell_type": "markdown",
   "id": "2453db7a",
   "metadata": {},
   "source": "## 7. Guardar Chunks Procesados en JSON"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc330752",
   "metadata": {},
   "outputs": [],
   "source": "# Save processed chunks to a JSON file\noutput_file = data_dir / \"rag_ingested_chunks.json\"\n\nprint(f\"\\nGuardando chunks en {output_file}...\")\n\ntry:\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(all_chunks, f, indent=4, ensure_ascii=False)\n    \n    print(f\"Archivo guardado exitosamente\")\n    print(f\"Total de chunks: {len(all_chunks)}\")\n    print(f\"Tamaño del archivo: {output_file.stat().st_size / 1024:.2f} KB\")\n    \nexcept Exception as e:\n    print(f\"Error al guardar archivo: {e}\")"
  },
  {
   "cell_type": "markdown",
   "id": "155b236e",
   "metadata": {},
   "source": "## Visualización de Resultados\n\nRevisar ejemplos de chunks procesados"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43a93e",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\n# Show summary information\nprint(\"Resumen de Chunks Procesados:\")\nprint(\"=\" * 60)\n\nif all_chunks:\n    # Create dataframe for analysis\n    df_summary = pd.DataFrame([\n        {\n            \"ID\": chunk[\"id\"],\n            \"Categoría\": chunk[\"category\"],\n            \"Tags\": \", \".join(chunk[\"tags\"]),\n            \"Longitud\": len(chunk[\"content\"]),\n            \"Has Embedding\": len(chunk[\"embedding\"]) > 0\n        }\n        for chunk in all_chunks[:10]  # Show first 10\n    ])\n    \n    print(df_summary.to_string(index=False))\n    \n    if len(all_chunks) > 10:\n        print(f\"\\n... y {len(all_chunks) - 10} chunks más\")\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(f\"Total de chunks: {len(all_chunks)}\")\n    \n    # Statistics by category\n    categories = {}\n    for chunk in all_chunks:\n        cat = chunk[\"category\"]\n        categories[cat] = categories.get(cat, 0) + 1\n    \n    print(f\"\\nDistribución por categoría:\")\n    for cat, count in sorted(categories.items()):\n        print(f\"   {cat}: {count} chunks\")\n    \n    # Tag statistics\n    all_tags = {}\n    for chunk in all_chunks:\n        for tag in chunk[\"tags\"]:\n            all_tags[tag] = all_tags.get(tag, 0) + 1\n    \n    print(f\"\\nDistribución de tags:\")\n    for tag, count in sorted(all_tags.items(), key=lambda x: x[1], reverse=True):\n        print(f\"   {tag}: {count} veces\")\nelse:\n    print(\"No hay chunks para mostrar. Asegúrate de que hay archivos PDF en el directorio /data\")"
  },
  {
   "cell_type": "markdown",
   "id": "94fb15a7",
   "metadata": {},
   "source": "## Ejemplo de Chunk Completo\n\nVisualizar la estructura detallada de un chunk procesado"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8436e1b",
   "metadata": {},
   "outputs": [],
   "source": "if all_chunks:\n    # Show first chunk as example\n    example_chunk = all_chunks[0]\n    \n    print(\"Ejemplo de Chunk Procesado:\")\n    print(\"=\" * 60)\n    print(f\"ID: {example_chunk['id']}\")\n    print(f\"Categoría: {example_chunk['category']}\")\n    print(f\"Source: {example_chunk['source']}\")\n    print(f\"Tags: {example_chunk['tags']}\")\n    print(f\"\\nContenido (primeros 300 caracteres):\")\n    print(f\"{example_chunk['content'][:300]}...\")\n    print(f\"\\nEmbedding (primeros 5 valores): {example_chunk['embedding'][:5]}\")\n    print(f\"Dimensión del embedding: {len(example_chunk['embedding'])}\")\nelse:\n    print(\"No hay chunks disponibles para mostrar\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}